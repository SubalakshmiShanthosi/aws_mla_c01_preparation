# Collect, Ingest and Store Data

Data Formats Supported
   Comma Separated Values
   Parquet - Apache Parquet is an open source, column-oriented data file format designed for efficient data storage and retrieval.
   ORC
   JSON
   Record IO
   Arvo 

Data Format Types and the usecases 

Parquet  - Read documentation to learn about the format


Types of Data

   ```rb
   Structured Data - Data is organized in a specific manner or schema 
   Contains rows and columns
   CSV, Databases, Excel Spreadsheet


   Unstructured Data - Data without predefined structure or schema
   Need to be preprocess for making it queryable
   Text file without file format, video or audio files, email and word processing documents, images


   Semi-Structured Data - Data is not organized as structured data but some level of structure in form of tags/hierarchies
   XML and JSON Files, Email headers, Log files in various formats

   ```

Properties of Data -

```rb
   1. Volume - Refers to amount of data the organization is working on for analysis 
      Characteristics: 
            Might be of size GB to Petabyte
            Challenges in storing, processing and analyzing high volumes of data
      Example data: 
            Social media data -user posts,images and videos
            Retailers collecting years of transactional data 
   
   2. Velocity - Speed at which the new data is    generated,collected and processed
         Like stream or batch processing data. 
      
      Characteristics: 
         High velocity requires real-time or near real time processing 

      Example - IoT devices sensor data - But the course doesnt have this topic on scope
      Trading applications

   3. Variety - Refers to the different types of structures and various soures of data
      Characteristics:
         Data can be structured, un-structured or semi-structured. 
         Data can come from multiple sources and are in various formats
      
      Examples:   
          For a business analyzing data from databases, email and JSON files
          Health care system - Electoric medical records, wearable health devices and patient feedback data.
      
```

Data Warehouse vs Data Lakes

 What is a data warehouse - 
   * Central information repository
   * Data Flow into data warehouses - __Structured data__ - Transactional system, relational databases 
   * Business Analyst, Data engineer, Data scientists access data through BI Tools, SQL Client.
   * ETL processing is done for getting data to get into datalakes 
   * Optimized for read-heavy operations

Example - Amazon Redshift


How it is different from Data Lake

Data Lake - Storage repository for vast amounts of __raw data__ in its native format

      Data Lake will have data as it is without any preprocessing
      Supports batch, real time and stream processing

Example : 
      S3 used as data lake for processing with other analytical service like AWS glue


Comparison between Data Warehouse and Data Lake

Schema - 
      Data Warehouse - Schema on write
      Data Lake - Schema on Read

Data Type - 
      Data Warehouse - Primarily structured data
      Data Lake - Both structured and unstructured data

Agility - 
      Data Warehouse: Less flexible as need to know the initial data schema
      Data Lake: More flexible as it has ability to hold raw unprocessed data

Processing - Data Warehouse - ETL
             Data Lake - ELT or just load for storage

Data LakeHouse
      Hybrid data architecture combines both best featured of data lake and data warehouse
Example - AWS Lake formation (S3 and Redshift spectrum)


Data Sources - JDBC vs ODBC

Open Database connectivity (ODBC) => platform dependent, language independent

Data sources - From database or Logs Raw (From systems like mainframe or OS logs), API's, Streaming Data (Kafka, Kinesis)


Data Formats - 
      
```rb
      1. CSV or TSV (Comma or tab delimiter, can also have another delimiter - like pipe)
      Easy to readable and editable
      Easy to import or export from databases
      
      2. JSON - Lightweight, text-based, human readable, semi-structured, data based on key-value pairs
      Configurayions and settings for structure
      Usecases where the data should have nested data structures 

      3. AVRO - Binary format, Stores both data and schema

      Big data and real-time processing 
      When schema changes its underlying data structure - AVRO can be of use


      AVRO - Data Serailization system that converts an object in memory to binary data

      4. Parquet - Columnar storage format optimized for analytics
      Effecient compression and encoding schemas.

      Parquet is useful for usecases ehere reading specific columns is neccessary 

      System - Hadoop, Apache Spark, Apache Hive, Redshift spectrum

```
   